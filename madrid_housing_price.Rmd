---
title: "LBB P4DS"
author: "theresia_londong"
date: "2023-02-11"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float:
      collapsed: true
    number_sections: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Real Estate Market in Madrid{.tabset .tabset-fade .tabset-pills}

## Introduction
[**Madrid**](https://goo.gl/maps/TBdfX8Gsz7YmFEUf6) is the capital and most populous city of Spain. The city has almost 3.4 million inhabitants and a metropolitan area population of approximately 6.7 million. It is the second-largest city in the European Union (EU), and its monocentric metropolitan area is the second-largest in the EU. The municipality covers 604.3 km2 geographical area.

Madrid is a center of attraction, the largest urban agglomeration on the Iberian Peninsula and a decisive engine of the Spanish economy with a lot of social dynamism. The city is not only the traditional political center of Spain, with parks and boulevards, but also a true metropolis in terms of culture, entertainment, sports, business and gastronomy. For example, it is home to two of the best soccer teams in the world. This makes Madrid attractive not only to institutional investors, but also to people looking for both the profitability of an investment and to enjoy the city’s impressive cultural, gastronomic and leisure offer. 

In this LBB project of Programming for Data Science with R, we would like to help potential buyers and sellers of real estate in Madrid to objectively assess the current market situation and find the best recommendation for properties according to their needs. This analyses are based on data collected from [kaggle](https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market).

## Data
Dataset used in this project is sourced from [kaggle](https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market). Data was collected through crawling popular real estate portals in Madrid.

Originally, this dataset has 58 columns but we will perform data wrangling to clean and prepare our dataset, using only the relevant columns for further analysis.

```{r echo=FALSE, results='hide'}
variable_names <- c("id", "subtitle", "sq_mt_built", "n_rooms", "n_bathrooms", "floor","buy_price","buy_price_by_area", "house_type_id", "built_year", "energy_certificate", "has_parking", "neighborhood_id")
description <- c("Unique ID", "Neighborhood & City", "Square meter built", "Number of Room", "Number of Bathroom", "House Level ", "Buy Price (in Euro)", "Buy Price per sqm (in Euro)", "Type of the house", "Built year", "Energy certificate type", "Access to Parking", "Information of Neighborhood and District ID (1 to 21)")

var_table <- data.frame(variable_names, description)
```

```{r echo=FALSE, results='hold'}
knitr::kable(var_table, caption = "List of Variables")
```

# {-}
# {-}

# Data Preparation

## Creating Initial Dataframe  

First we read the .csv file and use only the relevant columns, which then saved in a new dataframe called `house1`

```{r echo=TRUE, results='hide'}
#read .csv and save as object dataframe  
house <- read.csv('real_estate/houses_Madrid.csv', encoding = 'UTF-8')
head(house_1a <- house[, variable_names])
```
```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
#install package dplyr to manipulate character data
library(dplyr)
```

```{r echo=TRUE, results='hide'}
#turn all missing values to NA
house1 <- house_1a %>% mutate_all(na_if,"")
```

To perform string manipulation, we have to first install package called `stringr`, which allow us to extract information from column subtitle and create new columns called **neighborhood** and **city**.

```{r echo=TRUE, results='hide'}
library(stringr)

#extract neighborhood and city information from subtitle column
sub <- house1$subtitle %>% str_split(", ", n = 2, simplify = TRUE)
house1$neighborhood <- sub[,1]
house1$city <- sub[,2]

house2a <- subset(house1, select = -c(subtitle))
```

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
#manipulate `house_type_id` column and assign shorter value
type1 <- which(str_detect(house2a$house_type_id, "HouseType 1"))
type2 <- which(str_detect(house2a$house_type_id, "HouseType 2"))
type4 <- which(str_detect(house2a$house_type_id, "HouseType 4"))
type5 <- which(str_detect(house2a$house_type_id, "HouseType 5"))

house2a$house_type_id <- replace(house2a$house_type_id, type1, 'Type1')
house2a$house_type_id <- replace(house2a$house_type_id, type2, 'Type2')
house2a$house_type_id <- replace(house2a$house_type_id, type4, 'Type4')
house2a$house_type_id <- replace(house2a$house_type_id, type5, 'Type5')

```

```{r echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
#manipulate floor level and group level 1 to 9 into new category called upperground

uglvl <- which(str_detect(house2a$floor, '1|2|3|4|5|6|7|8|9'))
house2a$floor <- replace(house2a$floor, uglvl, 'Upperfloor')                    
```

```{r echo=TRUE, results='hide'}
#extract information of district ID from neighborhood_id column

distr <- strsplit(house1$neighborhood_id, split= 'District ')
df_distr <- as.data.frame(do.call(rbind, distr))
house2a$district_id <- df_distr[,2]
```

```{r echo=FALSE, results='hide'}
unique(house2a$district_id)
```

To understand the structure of our data frame, we use the `str()` function which result in data type information for each column, number of rows and columns. 

```{r echo=TRUE, results='hide'}
#remove column neighborhood_id & inspect structure of data
house2 <- subset(house2a, select=-c(neighborhood_id))
str(house2)
```

## Missing Value and Duplicates

Now that we have the correct initial dataframe, we can proceed to the next step in preparing our data, which is missing values and duplicates treatment.

First, let's find duplicate values (if any)!

```{r echo=FALSE, results='hold'}
house2[duplicated(house2),]
```

Next, find missing value, which previously market with NA, and decide which treatment to be employed for each variable.

```{r echo=TRUE, results='hide'}
#find which column(s) contain missing values
missing_col <- names(which(sapply(house2, function(x) any(is.na(x)))))
missing_col
```

```{r echo=TRUE, results='hold'}
#calculate missing value in each column
sum_na <- colSums(is.na(house2[,c(missing_col)]))
sum_na
```
```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
nrow(house2)
2670/nrow(house2)
```
Now we know that `built_year` column contains 11742 missing value out of total 21742 rows data in `house2`, or equal to 54% data. While `floor` contain **12%** missing values. This may lead to the next question, whether or not we should continue using `built_year` as our variable. As for missing values in the other 3 variables, `sq_mt_built`,`n_bathrooms` & `house_type_id`, we can either totally delete the rows, or assigning certain values to the missing values (i.e mean, mode, or zero value/0).

In our case, we decide to not using variable `built_year` in our analysis since it contains more than 50% of missing values, and we can drop the rows with missing values in columns `sq_mt_built`,`n_bathrooms`& `house_type_id` since they are insignificant in number and might hinder further statistical analysis process. To remove rows with NA values, we can apply `drop.na()` method from `tidyr` package. 

Column `floor` will be transformed into **factor** datatype, hence we will keep the missing values and classified them as **undefined**.

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library("tidyr")
```


```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
#remove column built_year
house3 <- subset(house2, select = -c(built_year))
head(house3)
```
```{r echo=TRUE, results='hide'}
#assign 'undefined' values to any missing values in`floor` & `house_type_id` columns

house3 <- house3 %>% 
          mutate(floor = coalesce(floor, 'undefined'))
          
```



```{r echo=TRUE, results='hide'}
#remove rows with remaining NA values
house_4a <- house3 %>% drop_na()
head(house_4a)
```

Continue by assigning correct data type to each column by using converting function like `as.character()`, `as.factor()`, `as.integer()`, `as.numeric()`, etc. Conversion into correct data type contribute to memory saving and enable data manipulation using specific function designed for each datatype.

```{r echo=TRUE, results='hide'}
#re-assign correct data type to column, if needed

house_4a$id <- as.character(house_4a$id)

house_4a <- house_4a %>% mutate_at(c('sq_mt_built','n_bathrooms'), as.integer)
house_4a <- house_4a %>% mutate_at(c('floor','house_type_id','energy_certificate', 'has_parking','neighborhood', 'city', 'district_id'), as.factor)
 
```

```{r echo=FALSE, results='hold'}
house_cln <- house_4a
str(house_cln)
```

Lastly, we save our clean dataframe in an object called `house_cln`.

# Data Explanation

You can find the complete explanation on Spanish terms used in our `house_cln` dataframe as below :

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
level  <-  c('Bajo', 'Entreplanta/Entreplanta exterior/Entreplanta interior','Sótano/Sótano exterior/Sótano interior', 'Semi-sótano/Semi-sótano exterior/Semi-sótano interior','Upperfloor', 'undefined')
level_desc <- c('ground level','Mezzanine level','Basement level','Semi-Basement level','N-th floor (1, 2, 3, etc)', 'undefined')
lvl_table <- data.frame(level, level_desc)
```

```{r echo=FALSE, results='hold'}
knitr::kable(lvl_table, caption = "Floor Level Explanation")
```


While you would think an apartment bathed in natural sunlight would be relatively easy to come by in sunny Spain, it’s actually a lot harder than you’d think, at least in densely populated cities. Many traditional apartments in Spain are composed of labyrinthine corridors leading to many small windowless rooms covered wall to wall with dark wooden furniture. Heavy shutters block out any remaining sun that dares to infiltrate. In fact, the buildings seem purposely designed to shut out sunlight. This does keep out the overwhelming summer heat, but in return creates a dark and depressing living space.

So if natural light is your priority, pay attention to the following two words: **Exterior** and **Interior**. If you want to see the sunshine peak through into your apartment for at least some of the day, you need to look for a **piso exterior**. That means your flat will look onto the street, giving you natural light, and maybe even have a nice view. If you go for a **piso interior,** your apartment will face away from the street and probably onto the inside of the apartment block. 

Another variable worth to mention is **House Type**. Of all sizes, with one or more floors, with or without a garden and in different environments. Below you can consult a list with the common types of house in our dataframe.

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
house_type <- c('Type 1: Pisos', 'Type 2: Casa o chalet', 'Type 4: Duplex', 'Type 5: Aticos')
house_type_desc <- c('A flat is a single-storey dwelling in which all the necessary facilities are distributed. They can have several rooms, a kitchen, living room and one or more bathrooms, but with no patio or outdoor garden',
                     'A chalet is an independent house with several floors, a garden and, in some cases, a swimming pool',
                     'This term refers to a house with two floors, connected to each other by a staircase.',
                     'The apartments that are located on the top floor of a building')

house_type_table <- data.frame(house_type, house_type_desc)
```

```{r echo=FALSE, results='hold'}
knitr::kable(house_type_table, caption = "House Type Explanation")
```


The last variable we need to discuss is the **Energy Certificate**, or the energy performance certificate, a report that describes how efficient a home is in terms of energy consumption. It assigns an energy rating to each home on a scale which ranges from "A" (the most efficient) to "G" (the least efficient). Like other European countries, since June 2013, anyone selling or renting a property in Spain, short or long term, needs an energy performance certificate. The introduction of this innovation is due to the requirements of the EU.

Apart from A to G energy rating, our `energy_certificate` column might contains other values like *en trámite* (in process), *no indicado* (not indicated) or *inmueble exento* (exempt property).

# Data Exploration

Start our exploration using `summary()` to extract the basic statistical information of each column in our `house_cln` dataframe.

```{r echo=TRUE, results='hold'}
summary(house_cln)
```
Now we are confident that every column has the information needed for further analysis.

## Distribution Analysis using Histogram and BoxPlot

### Analysis on building area in square meter (`sq_mt_built` column)
```{r echo=FALSE, results='hold'}
#analysis on distribution of building area in square meter data
hist(house_cln$sq_mt_built, main = 'Hist: Bulding Area', xlab = 'area in sqm')
```

We can see, the distribution is right-skewed and heavily distributed in the range of 0-200 sqm. For this reason, the central measurement use median (Q2) value instead of mean, for it's robust characteristic against outliers. 


### Analysis on number of room(s) and bathroom(s) per listing (`n_rooms` & `n_bathrooms`column)

```{r echo=FALSE, results='hold'}
par(mfrow=c(2,2))
hist(house_cln$n_rooms, main ='Hist : Room per House in Madrid', xlab='#of rooms')
boxplot(house_cln$n_rooms, horizontal = TRUE)
hist(house_cln$n_bathrooms, main = 'Hist : Bathroom per House in Madrid', xlab='#of bathrooms')
boxplot(house_cln$n_bathrooms, horizontal = TRUE)

```

Here, both variables have right-skewed distribution and heavily distributed in the low range region. For this reason, again, the central measurement use median (Q2) value instead of mean, for it's robust characteristic against outliers. 


### Analysis on Buy Price and Buy Price per Area

```{r echo=FALSE, results='hold'}
par(mfrow=c(2,2))
hist(house_cln$buy_price, main = 'Histogram of Buy Price in Madrid', xlab = 'buying price (Euro)')
boxplot(house_cln$buy_price, horizontal = TRUE)
hist(house_cln$buy_price_by_area, main ='Histogram of Buy Price per sqm in Madrid', xlab = 'buying price (Euro)')
boxplot(house_cln$buy_price_by_area, horizontal = TRUE)
```

Both variables, again, are right-skewed and heavily distributed in the low range region. For this reason, again, the central measurement use median (Q2) value instead of mean, for it's robust characteristic against outliers. Compare to the previous plot for number of rooms and bathrooms, here we can see the number of outliers are more prevalent. But inside the boxplot for **buying price per area**, data distribution is nearly symmetrical.


## Exploratory Analysis with Business Cases

**1.Define Top 10 districts with highest number of listed properties?**

```{r echo=FALSE, results='hold'}

#define top 10 districts with highest number of listed properties
no_listing <- as.data.frame(table(house_cln$district_id))
(top10_dtr <- head(no_listing[order(no_listing$Freq, decreasing=T),],10))

```

**2. Which are the top 10 districts with highest average (median) of buying price per area?**

```{r echo=FALSE, results='hold'}
#create aggregate table with district id & median of buy price per sqm 
median_buy_prc <- aggregate(buy_price_by_area ~ district_id ,data=house_cln, FUN = 'median')

#create an ordered table with 10 highest median buying price
head(median_buy_prc[order(median_buy_prc$buy_price_by_area, decreasing = T ),],10)
```

**3.Correlation of other variables to buying price per area, which variable have strongest correlation with it?**

**Ans** : as we knew the variable `buy_price_by_area` is a numerical data while the other variables are numerical and categorical. To find the correlation between 2 numerical values, we can use the `cor()` function, hence we will separate the `house_cln` data only for the numerical one and save it into new object calles `house_cl_num` then continue by finding the correlation with our target variable `buy_price_by_area`.

```{r echo=FALSE, results='hold'}

house_cln_num <- select_if(house_cln, is.numeric)
cor(house_cln_num)

```
A positive correlation between the number of rooms and bathrooms in a house with their price per area, but the correlation was too weak. It means that bigger house with more rooms is not necessarily always come with higher price. 

Now we can move to our categorical variables, and check their correlation with a numerical variable, `buy_price_by_area`, using Box plot or Kruskal-Wallis chi-squared.

```{r echo=FALSE, results='hide', message=FALSE, warning=FALSE}
select_if(house_cln, is.factor)  
```
**Boxplot Comparison**
```{r echo=FALSE, results='hold'}
# comparing the boxplot between group in floor with their buy price per sqm
library(ggplot2)

ggplot(data = house_cln, aes(x=floor, y=buy_price_by_area)) +
      geom_boxplot(aes(fill=floor)) +
  
      labs(title = 'Corr. Floor Level vs Buying Price per sqm',
       subtitle = NULL,
       x = 'Floor Fevel',
       y = NULL, #hapus sumbu y karena sudah jelas pada judul
       fill = 'Floor Level',
       caption = 'Source : Madrid Real-estate Site')
```

We find significant variation between median of each `floor` category to buy price per sqm, a lot of overlap between the boxes especially between numbered level 1 to 9 hence we merged those levels into one called Upperfloor for simplification purpose, but once you see the box plots of other floor levels, you will find lot more variety with less overlapping boxes. The floor level and buy price per sqm is definitely correlated but not in a weak way since some of the groups show us significant statistical differences.  

```{r echo=FALSE, results='hold'}
#compare house type with buing price per sqm
ggplot(data = house_cln, aes(x=house_type_id, y=buy_price_by_area)) +
      geom_boxplot(aes(fill=house_type_id)) +
  
  labs(title = 'Corr. House Type vs Buying Price per sqm',
       subtitle = NULL,
       x = 'House Type',
       y = NULL, #hapus sumbu y karena sudah jelas pada judul
       fill = 'House Type ID',
       caption = 'Source : Madrid Real-estate Site')
```

Here, we can see slighty significant differences between each category of `house_type_id` to buy price per sqm, if you compare the median value of each category, may say that there are correlation but insignificant one (low correlation).

```{r echo=FALSE, results='hold'}
#compare energy certificate with buying price per sqm
ggplot(data = house_cln, aes(x=energy_certificate, y=buy_price_by_area)) +
      geom_boxplot(aes(fill=energy_certificate)) +
  
  labs(title = 'Corr. Energy Certificate vs Buying Price per sqm',
       subtitle = NULL,
       x = NULL,
       y = NULL, #hapus sumbu y karena sudah jelas pada judul
       fill = 'Energy Certificate',
       caption = 'Source : Madrid Real-estate Site')
```

We can see a weak significant differences between each of the energy group especially if we regroup these into **A to D** energy group, **E & en tramite**, **F&inmueble exento&no indicato**, and **energy group G**. Same as previous comparison, we see lot of overlap between boxes, hence it is correlated but low ones. 

Alternatively, we can use **Kruskal-Wallis** test with `kruskal.test()` function.

```{r echo=TRUE, results='hold'}
#compare neighborhood id with buying price per sqm
kruskal.test(buy_price_by_area ~ house_type_id,
                    data = house_cln)
```
The null hypothesis (H0): The median is equal across all groups.
The alternative hypothesis: (H1): The median is not equal across all groups.

The p-value is extremely low, far less than the significant level of 0.05 hence it falls in rejection region. It can be concluded then, that there are significant difference between the treatment group, or the median is not equal across all group, which means the different neighborhoods leads to statistically significant differences in buying price per sqm. 

As for the dichotomous variable (iónly two values, TRUE/FALSE) like the one in `has_parking` column, we can use the **point-biserial correlation** test with `ltm()` package.

```{r echo=FALSE, results='hold', message=FALSE, warning=FALSE}
library(ltm)
biserial.cor(house_cln$buy_price_by_area, house_cln$has_parking)

```
It results a low correlation number between 2 variables. 

```{r echo=FALSE, results='hold', message=FALSE, warning=FALSE}
#compare district id with buying price per sqm
kruskal.test(buy_price_by_area ~ district_id,
                    data = house_cln)

#compare energy certificate with buying price per sqm
ggplot(data = house_cln, aes(y=district_id, x=buy_price_by_area)) +
      geom_boxplot(aes(fill=district_id)) +
  
  labs(title = 'Corr. District vs Buying Price per sqm',
       subtitle = NULL,
       x = NULL,
       y = 'District', #hapus sumbu y karena sudah jelas pada judul
       caption = 'Source : Madrid Real-estate Site') +
  
  theme(legend.position = "none") 
```

From the boxplot above, we can see significant difference between groups and not that much overlapping, hence these 2 variables are **strongly correlated**. 

**4. If a customer, with single/unmarried status & in their early employement year as an junior engineer at AECOM Madrid, ask for your recommendation as a real-estate consultant to buy his 1st property, what are your suggestions and why?**

**Ans** : to give the best recommendation, first we have to understand the profile of our customers and their requirements. 

Let's consider the priority feature for a single/unmarried employee in their first year employment,

* Priority Features : 
  + Buying price, as they're in the first year of employment moreover this is his first time buying property, we should consider their mortgage limit. In this case, **the buying price is more of a factor than a buying price per sqm**. 
  + Number of rooms, as they're single, we might want to **propose 1 - 2 bedrooms house** as their first house knowing we have the higher chance of mobility in younger-age worker compare to one with family hence we want to minimize the maintenance cost. For this reason we should go with house type_1 : Pisos, type_4 : duplex or type 5 : Atticos.

* Nice to Have :
  + Younger generation prefer to not wasting their time commuting, hence the **favorable location** is the one with well serve connectivity to their office or down-town city centre.  
  + Younger generation use less and less private transportation, especially if they live close to city center / has good access to public transport, hence the **parking lot is no longer mandatory**.

Then, we consider their financial situation. In average, a junior engineer in AECOM Madrid made 30K Euro annually, source : [Glassdoor](https://www.glassdoor.co.uk/Salaries/madrid-junior-engineer-salary-SRCH_IL.0,6_IM1030_KO7,22.htm), which equal to Nett. amount of ~1900 Euro per month. 
Based on this information, we then setup the upper limit for mortgage to 5 times his annual salary, **150K Euro**.

```{r echo=TRUE, results='hide'}
#filter only those properties within his budget
house_budget1 <- house_cln[house_cln$buy_price <= 150000,]

#filter based on the desired house type
(type125_budget1 <- house_budget1[house_budget1$house_type_id %in% c('Type1', 'Type2', 'Type5'),])

#create and aggregate table to show median of buying price per sqm per house type per district 
(agg_type125_budget1 <- aggregate(buy_price_by_area ~ district_id, data = type125_budget1, FUN = 'median'))

```

Now that we have the list of properties which satisfy 2 of our main constrains, we can then group those properties based on the *nice to have* features, first the location,  

This customer works at AECOM, Madrid. The office is located in C. de Alfonso XII, 62, Madrid ( Lat 40.40911870940878, Long -3.689179361369044). Based on this information, we can then create an interactive map to see the nearby district and match with our list of Top 10 districts with the lowest buying price per sqm.  

```{r echo=FALSE, results='hold'}

# Find top 25 district with lowest median value of buying price per sqm 
top10_type125_budget1 <- head(agg_type125_budget1[order(agg_type125_budget1$buy_price_by_area, decreasing = F),], 10)
top10_type125_budget1
```
```{r echo=FALSE, results='hide'}
# install.packages("leaflet")
library(leaflet)

# get icon
ico <- makeIcon(
    iconUrl = "https://purepng.com/public/uploads/large/purepng.com-aecom-logologobrand-logoiconslogos-251519939890kydbk.png",
    iconWidth=177/2, iconHeight=41/2
)

# make dummy data
loca <- data.frame(lat= 40.40911870940878,
                   lng= -3.689179361369044)

# check data
loca
```

```{r echo=FALSE, results='hold'}
# create a leaflet map widget
map1 <- leaflet()

# add tiles from open street map
map1 <- addTiles(map1)

# add markers
map1 <- addMarkers(map1, data = loca, icon=ico)

map1
```


From the map above, we can classify the 1st-ring district from AECOM office based on the distance that are : Salamanca, Retiro, and Arganzuela, The 2nd ring district will be : Usera, Puente de Vallecas, Moratalaz, Chamberi and Latina. These districts are the most accessible from his office, and from our list above, we can see that district **Usera, Puente de Vallecas, Latina and Moratalaz** are among the Top 10 district with lowest median buying price per sqm.

So **the recommendation** is to look at the listed properties in these 4 districts, with their reasonable price per sqm and distance to the office and city center. **Puente de Vallecas** has the biggest number of 648 available properties with the lowest median value of buying price per sqm (< 2000 Euro per sqm). 

```{r echo=FALSE, results='hold'}
#Filter based on the 4 most sought after districts
recom1_district <- type125_budget1[type125_budget1$district_id %in% c('18: Usera','13: Puente de Vallecas', '12: Moratalaz','10: Latina'),]

#Order of district based on number of available properties
agg_recom1 <- aggregate(id~district_id,data=recom1_district, FUN = 'length')
agg_recom1[order(agg_recom1$id, decreasing=TRUE),]

```

**5. If a family of 4 looking for a house for them to settle down and stay for a long term, both parents work for quite some years already, what would be your recommendation as a real estate consultant?**

Unlike the previous client who is single and in his early employment year, the family with 4 has certain characteristic and requirements for their long-term family home. 

* Priority Features:
  + Type of home. The family would much prefer the detached home than flat or duplex, let alone studio house. They appreciate more outdoor spaces for the kids to play or maybe for having a pet in the future.
  + The family of needs at least 2 bedrooms, kitchen & a living room in their house. 
  + Upper limit mortgage for the family of 4 usually is higher than the previous one, moreover they have time to save for more deposit money, therefore the price constrain is more relax here. With average household income of 60K euro annually, this family could request for a mortgage up to 5x of their annual income, or up to 300K Euro.  
  
* Nice to have Feature:
  + The family with 4 will require car to travel especially if their home is located in the outer ring 7 sub-urban area, therefore a parking lot is needed.
  + Preference of house type 2 and 4

```{r echo=TRUE, results='hide'}
# filter the properties with buying price within their budget of 300K Euro
house_budget2 <- house_cln[house_cln$buy_price <= 300000,]

#house with number of room more than 4
house_budget2_4r <- house_budget2[house_budget2$n_rooms > 3,]

#filter property based on the house type, eliminate house type 5
type124_budg2 <- house_budget2_4r[house_budget2_4r$house_type_id %in% c('Type1','Type2','Type4'),]

```

The following listings are our **first recommendation** which satisfy both their priority features and the nice-to-have ones.
```{r echo=FALSE, results='holds'}
park_budget2_type24 <- house_budget2_4r[house_budget2_4r$house_type_id %in% c('Type2','Type4') & house_budget2_4r$has_parking %in% 'True' ,]
park_budget2_type24[, c('id', 'sq_mt_built', 'n_rooms', 'n_bathrooms', 'buy_price', 'buy_price_by_area', 'house_type_id', 'neighborhood', 'district_id')]
```


While these are the recommendations based on where to look for property which satisfy their priority features only + parking availability. 

```{r echo=TRUE, results='hide'}
#filter property based on the parking lot availability as our first priority to be offered
park_budg2 <- type124_budg2[type124_budg2$has_parking %in% 'True',]
```

```{r echo=TRUE, results='holds'}
#Median value of buying price & buying price per square meter per district from lowest to highest
agg_park_budg2 <- aggregate(cbind(buy_price,buy_price_by_area) ~ district_id, data=park_budg2, FUN = 'median')

#Lowest to Highest buy price per sqm
agg_park_budg2[order(agg_park_budg2$buy_price_by_area, decreasing=FALSE),]

#Based on number of properties per district per type of house
agg_list_park_budg2 <- aggregate(house_type_id ~ district_id, data=park_budg2, FUN = 'length')
agg_list_park_budg2[order(agg_list_park_budg2$house_type_id, decreasing = TRUE),]
```

**The recommendation** will be the first 3 properties which satisfies both priority and nice-to-have features. Otherwise, we have other list of 80 properties distributed in 11 districts which satisfy the priority feature. Among them, properties in districts **Villaverde and Puente de Vallecas** has the most options of available properties as well as the lowest buying price per sqm, under 2000 Euro per sqm.   


**6. Could you define the characteristic of certain area or neighborhoods based on the property profile listed in your dataset?**

**Ans** : No, our dataset has it's limitation to accurately describe a community. A community described by combination of various factors such as public transport, school availability, available medical infrastructure, available family & leisure activities, available commercial sites, criminal rate, demographic, etc. But our dataset could classifies community based on their customer profile as demonstrated in exploration no #7 and #8.   


# References

1. <https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market>
2. <https://www.kensington-international.com/madrid/en/news/madrid-real-estate-market-report-2021-2022/>
3. <https://acrossthewater.blog/a-beginners-guide-to-renting-an-apartment-in-spain/>

